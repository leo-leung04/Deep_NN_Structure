Top 20 layer types by task:

feature-extraction:
  Linear: 15259 (34.9%)
  Dropout: 5593 (12.8%)
  LayerNorm: 4916 (11.2%)
  GELUActivation: 2102 (4.8%)
  BertSelfOutput: 1080 (2.5%)
  BertSdpaSelfAttention: 1080 (2.5%)
  BertAttention: 1080 (2.5%)
  BertIntermediate: 1080 (2.5%)
  BertOutput: 1080 (2.5%)
  BertLayer: 1080 (2.5%)
  Embedding: 565 (1.3%)
  RobertaSdpaSelfAttention: 360 (0.8%)
  RobertaAttention: 360 (0.8%)
  RobertaIntermediate: 360 (0.8%)
  RobertaOutput: 360 (0.8%)
  RobertaLayer: 360 (0.8%)
  RobertaSelfOutput: 360 (0.8%)
  T5LayerNorm: 309 (0.7%)
  NewGELUActivation: 250 (0.6%)
  Conv1D: 192 (0.4%)

image-text-to-text:
  Linear: 5563 (35.2%)
  Dropout: 2293 (14.5%)
  LayerNorm: 2041 (12.9%)
  GELUActivation: 793 (5.0%)
  BlipTextSelfOutput: 634 (4.0%)
  BlipTextSelfAttention: 634 (4.0%)
  BlipTextAttention: 634 (4.0%)
  BlipAttention: 341 (2.2%)
  BlipEncoderLayer: 341 (2.2%)
  BlipMLP: 341 (2.2%)
  BlipTextOutput: 317 (2.0%)
  BlipTextIntermediate: 317 (2.0%)
  BlipTextLayer: 317 (2.0%)
  Embedding: 79 (0.5%)
  GitLayer: 72 (0.5%)
  GitOutput: 72 (0.5%)
  GitIntermediate: 72 (0.5%)
  GitAttention: 72 (0.5%)
  GitSelfOutput: 72 (0.5%)
  GitSelfAttention: 72 (0.5%)

audio-classification:
  Linear: 10717 (29.5%)
  Dropout: 8587 (23.6%)
  GELUActivation: 5495 (15.1%)
  LayerNorm: 3611 (9.9%)
  Conv1d: 1264 (3.5%)
  _WeightNorm: 948 (2.6%)
  ParametrizationList: 948 (2.6%)
  Wav2Vec2FeedForward: 924 (2.5%)
  Wav2Vec2NoLayerNormConvLayer: 462 (1.3%)
  WhisperSdpaAttention: 276 (0.8%)
  Wav2Vec2LayerNormConvLayer: 232 (0.6%)
  ASTLayer: 221 (0.6%)
  ASTSelfAttention: 221 (0.6%)
  ASTSelfOutput: 221 (0.6%)
  ASTIntermediate: 221 (0.6%)
  ASTOutput: 221 (0.6%)
  ASTAttention: 221 (0.6%)
  Wav2Vec2SamePadLayer: 107 (0.3%)
  Wav2Vec2FeatureEncoder: 106 (0.3%)
  HubertNoLayerNormConvLayer: 102 (0.3%)

automatic-speech-recognition:
  Dropout: 9005 (31.3%)
  Linear: 6076 (21.1%)
  GELUActivation: 5380 (18.7%)
  LayerNorm: 2600 (9.0%)
  Conv1d: 1135 (4.0%)
  _WeightNorm: 875 (3.0%)
  ParametrizationList: 875 (3.0%)
  Wav2Vec2LayerNormConvLayer: 704 (2.5%)
  WhisperSdpaAttention: 552 (1.9%)
  Wav2Vec2FeedForward: 384 (1.3%)
  Wav2Vec2NoLayerNormConvLayer: 198 (0.7%)
  WhisperDecoderLayer: 184 (0.6%)
  WhisperEncoderLayer: 184 (0.6%)
  Wav2Vec2FeatureEncoder: 122 (0.4%)
  Wav2Vec2SamePadLayer: 122 (0.4%)
  GroupNorm: 34 (0.1%)
  Wav2Vec2GroupNormConvLayer: 33 (0.1%)
  Speech2TextAttention: 24 (0.1%)
  SpeechT5Attention: 24 (0.1%)
  ModuleList: 21 (0.1%)

image-feature-extraction:
  Linear: 875 (30.9%)
  Dropout: 357 (12.6%)
  LayerNorm: 260 (9.2%)
  GELUActivation: 124 (4.4%)
  ViTIntermediate: 112 (3.9%)
  ViTLayer: 112 (3.9%)
  ViTOutput: 112 (3.9%)
  ViTAttention: 112 (3.9%)
  ViTSelfOutput: 112 (3.9%)
  ViTSelfAttention: 112 (3.9%)
  Conv1D: 96 (3.4%)
  RMSNorm: 50 (1.8%)
  ImageGPTLayerNorm: 49 (1.7%)
  ImageGPTAttention: 24 (0.8%)
  AIMv2Block: 24 (0.8%)
  AIMv2Attention: 24 (0.8%)
  ImageGPTBlock: 24 (0.8%)
  ImageGPTMLP: 24 (0.8%)
  QuickGELUActivation: 24 (0.8%)
  AIMv2SwiGLUFFN: 24 (0.8%)

image-segmentation:
  Linear: 7364 (22.9%)
  LayerNorm: 3574 (11.1%)
  Dropout: 3364 (10.5%)
  Conv2d: 3156 (9.8%)
  BatchNorm2d: 1147 (3.6%)
  GELUActivation: 1126 (3.5%)
  ReLU: 1086 (3.4%)
  SegformerAttention: 916 (2.8%)
  SegformerMixFFN: 916 (2.8%)
  SegformerSelfOutput: 916 (2.8%)
  SegformerEfficientSelfAttention: 916 (2.8%)
  SegformerDWConv: 916 (2.8%)
  SegformerLayer: 916 (2.8%)
  SegformerDropPath: 890 (2.8%)
  ResNetConvLayer: 539 (1.7%)
  REBNCONV: 448 (1.4%)
  Identity: 364 (1.1%)
  Sequential: 300 (0.9%)
  ModuleList: 239 (0.7%)
  ResNetBottleNeckLayer: 176 (0.5%)

fill-mask:
  Linear: 10138 (34.8%)
  LayerNorm: 3468 (11.9%)
  Dropout: 3389 (11.6%)
  GELUActivation: 1625 (5.6%)
  BertSdpaSelfAttention: 669 (2.3%)
  BertSelfOutput: 669 (2.3%)
  BertAttention: 669 (2.3%)
  BertIntermediate: 669 (2.3%)
  BertOutput: 669 (2.3%)
  BertLayer: 669 (2.3%)
  RobertaIntermediate: 438 (1.5%)
  RobertaSdpaSelfAttention: 438 (1.5%)
  RobertaLayer: 438 (1.5%)
  RobertaOutput: 438 (1.5%)
  RobertaAttention: 438 (1.5%)
  RobertaSelfOutput: 438 (1.5%)
  Embedding: 370 (1.3%)
  XLMRobertaSdpaSelfAttention: 100 (0.3%)
  XLMRobertaSelfOutput: 100 (0.3%)
  XLMRobertaAttention: 100 (0.3%)

